{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116ed6e1-7e2b-482a-94c1-b712a32e5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75ca4bb-5ab8-440d-989c-ec3211433e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.llm_engine import createGPTModel\n",
    "from engine.data_loader import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed51857b-37d9-4ede-a524-20e84ce884fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162af1b4-d543-4541-a8fd-9e33f19fa88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 256,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"kqv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55ca1ad-510b-4ce5-92c3-a115047275de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createGPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98360119-5192-417a-8933-c018a33cceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataloader_v1(txt, batch_size=4 , context_length=256, \n",
    "#                          stride=256, shuffle=True, drop_last = True, \n",
    "#                          num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c9b75-8ac7-4f4e-a148-8e6eb734a188",
   "metadata": {},
   "source": [
    "## Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965a9b13-c18a-444c-b61c-09b75eb322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path , \"r\" , encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1712168c-15ea-491d-95b0-79d71f0fae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d005b21c-1ead-4d56-b411-415729e67e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[ : split_idx]\n",
    "val_data = text_data[split_idx : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3226976b-e524-4195-8388-6575e0260bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    context_length=256,\n",
    "    stride=256,\n",
    "    drop_last = True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    context_length=256,\n",
    "    stride=256,\n",
    "    drop_last = False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2d0d3b-b31f-4976-bb49-7a0913adcef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef895b53-476f-4e0d-ac62-65f289a056cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d382fbb1-4e56-4218-b15e-df77aea1319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "\n",
    "batch.append(torch.tensor([6109,  3626,  6100,   345]))\n",
    "batch.append(torch.tensor([6109,  1110,  6622,   257]))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c83d5c-614c-46f4-9001-75fa055f255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1735,  0.1922, -0.4804,  ...,  0.0184,  0.5818, -0.1149],\n",
      "         [-0.8016, -0.0366, -0.6047,  ...,  0.2760, -0.4721, -0.4356],\n",
      "         [-0.3624, -0.3774, -0.6089,  ...,  0.8500,  0.5048,  0.1919],\n",
      "         [ 0.0605, -0.4519, -0.5605,  ...,  0.3887,  0.8183,  1.4593]],\n",
      "\n",
      "        [[ 0.4189,  0.5406, -0.9069,  ...,  0.1814,  0.7552, -0.1245],\n",
      "         [-0.2921, -0.2976, -0.5443,  ..., -0.7706, -1.6711, -0.1323],\n",
      "         [ 0.2992, -0.5517, -0.3342,  ...,  0.6089,  1.4291,  0.4221],\n",
      "         [ 0.5685,  0.0318, -1.3728,  ...,  0.2945, -0.1885, -0.1910]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c5bd3-bff5-4a2c-bd77-acfa1247e184",
   "metadata": {},
   "source": [
    "## Total model Prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8170fe-5f93-4dfe-aa63-9948f6374d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749c5aa3-e67a-46e8-b345-c44389458720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4      \n",
    "total_size_mb = total_size_bytes / (1024 * 1024)    \n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2bf991-7358-4de7-b5d5-24042701cbe8",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57274c3a-9a39-434c-a919-a87f1f28ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model , idx, max_new_token, context_size):\n",
    "    for _ in range(max_new_token):\n",
    "        idx_cond = idx[ : , -context_size : ]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[ : , -1, :]\n",
    "        probs = torch.softmax(logits , dim=-1)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next) , dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446c3c37-09fa-46a7-965e-2ccb9bb0461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ef55f3c-23b0-4768-8eb4-b725c52ad754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [39, 4178, 11, 314, 1101, 7844, 680, 13308, 11, 3058, 314, 1101, 5670, 319, 2615, 290, 29682, 220]\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hii, I'm Ashish Raj, currently I'm focused on building and deploying \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c3767d-d490-4ae8-8c7d-9804f0fddeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_tensor.shape: torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "727f17ce-de7a-4787-a798-b8b94a9702d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[   39,  4178,    11,   314,  1101,  7844,   680, 13308,    11,  3058,\n",
      "           314,  1101,  5670,   319,  2615,   290, 29682,   220,  9464, 14737,\n",
      "         29760, 22344, 11245, 45370]])\n",
      "Output length: 24\n"
     ]
    }
   ],
   "source": [
    "model.eval()                 \n",
    "out = generate_text(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_token=6, \n",
    "    context_size = 4\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d912b84-3a2b-4022-9f2c-79180b78b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii, I'm Ashish Raj, currently I'm focused on building and deploying left Mason cryptocurrenciesosaurs003 embodies\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddeddf1-2f8c-4cf1-a9ca-c726c3007dec",
   "metadata": {},
   "source": [
    "## Training and Validation Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b150d4ef-5490-4247-a939-aaecabba3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)        \n",
    "    target_batch = target_batch.to(device)      \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "     logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3876dbf1-ca8f-4310-981e-4a580d686ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches , len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06460793-4e55-468f-8b0c-a05ef0a98114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.99063385857476\n",
      "Validation loss: 10.96821117401123\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  \n",
    "with torch.no_grad():                                       \n",
    "    train_loss = cal_loss_loader(train_loader, model, device)   \n",
    "    val_loss = cal_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18fe06d-227c-4961-8297-779a2a3a65fa",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711d9897-9cdc-420a-9054-3871ffae7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model , idx, max_new_token, context_size):\n",
    "    for _ in range(max_new_token):\n",
    "        idx_cond = idx[ : , -context_size : ]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[ : , -1, :]\n",
    "        probs = torch.softmax(logits , dim=-1)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next) , dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7108493a-bfe7-44a9-838e-01f93bf0f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a151c0e-5957-445e-92b1-6db986fd7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054751e8-4040-42d1-992d-53713b49395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_context = \"Every effort moves you \"\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d149fa6e-929d-41e2-9de6-f193b3298a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = cal_loss_loader(\n",
    "            train_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "        val_loss = cal_loss_loader(\n",
    "            val_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss , val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45d4cb03-13ad-4a56-885e-28acce34abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text(\n",
    "            model=model, idx=encoded, \n",
    "            max_new_token=50, context_size=context_size\n",
    "            )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89510005-d93f-4389-8bb5-f3150cfc8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, traget_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, traget_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel() # torch.numel() is a function that returns the total number of elements in a given tensor. It calculates the product of all dimensions of the tensor, effectively counting every individual value stored within it\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                  f\"Train loss {train_loss:.3f}, \"\n",
    "                  f\"Val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(                     \n",
    "            model, tokenizer, device, start_context)\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aec2da-065e-4222-a909-dca48783ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
